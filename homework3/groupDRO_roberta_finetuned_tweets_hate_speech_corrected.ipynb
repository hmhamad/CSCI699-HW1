{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"F51oYwCRFr5g","outputId":"bfda3772-230d-40ab-8363-d7978cebd771","executionInfo":{"status":"ok","timestamp":1651648301937,"user_tz":420,"elapsed":29388,"user":{"displayName":"Han Kyul Kim","userId":"01874191508261431132"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wilds\n","  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 44.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 38.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 126 kB 34.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (4.64.0)\n","Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.7/dist-packages (from wilds) (2022.1)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from wilds) (0.12.0+cu113)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.11.0+cu113)\n","Collecting scipy>=1.5.4\n","  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n","\u001b[K     |████████████████████████████████| 38.1 MB 1.0 MB/s \n","\u001b[?25hCollecting outdated>=0.2.0\n","  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.0.2)\n","Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.21.6)\n","Collecting ogb>=1.2.6\n","  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 8.3 MB/s \n","\u001b[?25hCollecting pillow>=7.2.0\n","  Downloading Pillow-9.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 64.4 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from wilds) (1.3.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.2.6->wilds) (1.15.0)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb>=1.2.6->wilds) (1.24.3)\n","Collecting littleutils\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->wilds) (2.23.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->wilds) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->wilds) (1.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->wilds) (4.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->wilds) (2.10)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=20399329e0570334d38619b8ac898f9b398b1cb505ca1efea5ebc2fc909443aa\n","  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n","Successfully built littleutils\n","Installing collected packages: scipy, littleutils, pillow, outdated, ogb, wilds\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1 pillow-9.1.0 scipy-1.7.3 wilds-2.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 29.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 73.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 60.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.6 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=476870575a9fc8e2633a0271c5ba9af023c571e2f3c5435fcf18613a754842ce\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n","\u001b[K     |████████████████████████████████| 7.9 MB 44.8 MB/s \n","\u001b[?25hCollecting pillow==7.2.0\n","  Downloading Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n","\u001b[?25hInstalling collected packages: pillow\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 9.1.0\n","    Uninstalling Pillow-9.1.0:\n","      Successfully uninstalled Pillow-9.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed pillow-7.2.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}}],"source":["!pip install wilds\n","!pip install transformers\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n","!pip install pillow==7.2.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N29SZtbaPWeK"},"outputs":[],"source":["import dill\n","import os\n","\n","import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn import preprocessing\n","import torch\n","from torch import nn\n","from transformers import RobertaModel, RobertaTokenizer\n","from transformers import AdamW\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","from tqdm import tqdm"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTpXruIW7XA3","executionInfo":{"status":"ok","timestamp":1651682151122,"user_tz":420,"elapsed":3304,"user":{"displayName":"Han Kyul Kim","userId":"01874191508261431132"}},"outputId":"42cdd728-3f39-45c7-877c-3ebaeafc6666"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHRQ9J_wFxLj","executionInfo":{"status":"ok","timestamp":1651648333819,"user_tz":420,"elapsed":23444,"user":{"displayName":"Han Kyul Kim","userId":"01874191508261431132"}},"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["6b32ad6b10f543e8bc49851e16c1ce9e","2bf91d720fe14e27acd2d375af3fb1f1","62f59acb0d124f6385e2b9a0c54f85cd","1022ac87ba3d4cc0892452194f00406e","9f4624370d6540c0b9afc1d4c5796e97","a8518c15001c4a7b8c000ba39cb15a69","a62aadd82fc749ecbb29af1518618bf7","f564e8ccbb43420a9f9e1290b7915dc2","b5c111bb676f4c06b91d4bedea1e778d","de53d9765d1f4e9a930aeec6c3dbad0c","f998fdbe823b466aa1f4bff240ef49a8"]},"outputId":"09bd90c3-407c-4369-ca3a-9a27794337ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading dataset to data/civilcomments_v1.0...\n","You can also download the dataset manually at https://wilds.stanford.edu/downloads.\n","Downloading https://worksheets.codalab.org/rest/bundles/0x8cd3de0634154aeaad2ee6eb96723c6e/contents/blob/ to data/civilcomments_v1.0/archive.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/90644480 [00:00<?, ?Byte/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b32ad6b10f543e8bc49851e16c1ce9e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting data/civilcomments_v1.0/archive.tar.gz to data/civilcomments_v1.0\n","\n","It took 0.3 minutes to download and uncompress the dataset.\n","\n"]}],"source":["from wilds import get_dataset\n","\n","dataset = get_dataset(dataset=\"civilcomments\", download=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkZxxo4IPZKa","colab":{"base_uri":"https://localhost:8080/","height":144,"referenced_widgets":["d97ce080ec154d709c94dbe4a8d0c438","eb85a75cc7264b85912cda280739aa07","bf39e55f3b964d75af10e09e5aa07425","21b9df91c02841068b8ad5c28ed9e9db","f2c031f1986e4363b7181bbbbdcb4fc8","1b57117704fb4b2aa8e007a2fbb21228","6084c8701e5742b28207df5b3c98128e","11064a9a79cf4f86849f453f2980f863","d62fd52723114272975191b19a020691","6c0fb3c7d1fe4882892c822bccea98ed","2e3580f2593247489af95d1f8b6e8fd8","3d5bcfed84314667af43ebb0229c5fbd","48b14ad5ead84b00887fc4153409c68d","943138710e204e7dad11089b20a98ed6","9c777e19dd2d450192135e02fcc1b341","bc60116278ec4e89bc193d81f5a36216","d318ec5555cc4fa4a167729bdb017d31","2cee70c7bb414cbbbdf20690045feba2","33251e95ea4b42b0867061dfeb1ecdb7","833d74219db54a35aa575c3ae0592114","29a4c253c3bb43af8b8d72633ac758ba","e77bc7140a1541f584d8872554d34bfc","765293faad974c03971bb3a2811b4290","122201fb63204aa0a54a4d3ccf86d05e","1a1a04bb77ee4f6186fc6e1a6175c42e","349d957b327d4aa99526d32f26684c4c","a185fba62ae2465ea7fa4808947965da","2f76ae4ef25b499e9c7089e78ff946ad","1914fd59c5764ad08e74e141eee0df31","620c5ce50e2349f6ac72ce78de3c2661","12133a9573344dd7824a3d38634e894a","e5bf34ff38c049c48803c45b94e60c8c","63ced2dcecf64e1583ac216d51df9e5a","ccd22bbdd0684b14aae8aba6d6feb759","095d03243fbd48abb7028a40a5189a03","467148aae83b44f583ccecd4744658ae","c07de1b836ec4f0babd8231971983249","1113ae58f9b943d09f6bf05ca6ce5f77","f2cfda63d4ef406dad587a99ddb25afd","a1228479026145f29b3907acd342461f","2ad83da36c31467fb16af45dc9c5858e","6c4d23da48e04d5284e0c815e2c04bf4","1ce51963f3b2487783d40ed62eccc714","046a7dc6b1314b94aa5a2f85a0f72eb9"]},"executionInfo":{"status":"ok","timestamp":1651648433877,"user_tz":420,"elapsed":92854,"user":{"displayName":"Han Kyul Kim","userId":"01874191508261431132"}},"outputId":"6d708582-1b98-4494-94fa-0a2f71b7c754"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97ce080ec154d709c94dbe4a8d0c438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d5bcfed84314667af43ebb0229c5fbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"765293faad974c03971bb3a2811b4290"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/588 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd22bbdd0684b14aae8aba6d6feb759"}},"metadata":{}}],"source":["test = dataset.get_subset(\"test\")\n","\n","testX = [data[0] for data in test]\n","testY = torch.stack(([data[1] for data in test]))\n","testMeta = torch.stack(([data[2] for data in test]))\n","\n","pretrained_path = 'cardiffnlp/twitter-roberta-base-hate'\n","\n","\n","# Tokenizers used in the domain adapted versions of RoBERTa are identical to roberta-base\n","roberta_tokenizer = RobertaTokenizer.from_pretrained(pretrained_path)\n","encoded_testX = roberta_tokenizer(testX, truncation=True, max_length = 300, padding='max_length', return_tensors = 'pt', return_attention_mask = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtKqMeESYZkS"},"outputs":[],"source":["import random\n","\n","from wilds.common.data_loaders import get_train_loader\n","from wilds.common.grouper import CombinatorialGrouper\n","\n","target_groups = ['black', 'y']\n","n_groups = len(target_groups) * 2\n","batch_size = 16\n","\n","grouper = CombinatorialGrouper(dataset, target_groups)\n","\n","train = dataset.get_subset(\"train\")\n","train_loader = get_train_loader(\n","    \"group\", train, grouper=grouper, n_groups_per_batch=n_groups, batch_size=batch_size\n",")\n","\n","\n","test_dataset = TensorDataset(encoded_testX['input_ids'],encoded_testX['attention_mask'], testY, testMeta)\n","test_dataloader = DataLoader(\n","            test_dataset,\n","            batch_size = batch_size\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvzBZNPuIYe-","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c70c1ba369ad4aeda31aa32c38d59f59","267e944116154affbaeb86b71b113df8","50a832c3a6fb4e6cba70939b45038f2e","a339c186931043fcad4194efb637f278","b4f402b84c584c67a5f256714085ffc8","7b6e6304facb45eb85f39976d611421d","c2fa3636ab40445da36682777d0e923b","95b39bba22c84fbdb2805489758148e5","a966bf5a040a418fb0fa31e3fca6ac80","486396b80928466db7d372f969fbaa34","d37a736d32794c9e8600404a4b6a793a"]},"executionInfo":{"status":"ok","timestamp":1651648476709,"user_tz":420,"elapsed":42835,"user":{"displayName":"Han Kyul Kim","userId":"01874191508261431132"}},"outputId":"2b0a4a40-8a4f-4073-8c31-16c2fe7a8529"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c70c1ba369ad4aeda31aa32c38d59f59"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-hate were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-hate and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["CustomRoberta(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (hidden_layer): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (activation): ReLU()\n","  (output_layer): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":6}],"source":["from torch import nn\n","from transformers import RobertaModel, RobertaTokenizer\n","\n","# RobertaForSequenceClassification could also be used.\n","# Drop out rate as used in the paper\n","class CustomRoberta(nn.Module):\n","    def __init__(self):\n","          super(CustomRoberta, self).__init__()\n","          self.roberta = RobertaModel.from_pretrained(pretrained_path, output_hidden_states = True)\n","          self.hidden_layer = nn.Linear(768, 768)\n","          self.dropout = nn.Dropout(0.1)\n","          self.activation = nn.ReLU() # or tanh()\n","          self.output_layer = nn.Linear(768, 2)\n","          \n","    def forward(self, d_ids, d_mask):\n","          # index 1 represents the pooled_output, the cls token.\n","          sequence_output = self.roberta(input_ids = d_ids,attention_mask=d_mask)[1]\n","          sequence_output = self.dropout(sequence_output)\n","          hidden_output = self.hidden_layer(sequence_output)\n","          dropout = self.dropout(hidden_output)\n","          act = self.activation(dropout)\n","          output = self.output_layer(act)\n","\n","          return output\n","\n","model = CustomRoberta()\n","model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0r60JuNbEGh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651648476710,"user_tz":420,"elapsed":7,"user":{"displayName":"Han Kyul Kim","userId":"01874191508261431132"}},"outputId":"b60127b5-db2c-4043-c02a-f47d337b941d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["torch.manual_seed(42)\n","epochs = 5\n","\n","optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n","group_weights = [1] * (batch_size//n_groups)"]},{"cell_type":"code","source":["import math\n","\n","def update_dro_group_weights(weights, group_idx, loss, eta_q = 0.01):\n","  new_weight = weights[group_idx] * math.exp(eta_q * loss.item())\n","  weights[group_idx] = new_weight\n","  return [weight/sum(weights) for weight in weights]"],"metadata":{"id":"JzJ9mLQo7Efp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQUt1YgOc7YN"},"outputs":[],"source":["def get_loss_value(model, loader, device, cal_f1=True, benchmark_val=False):\n","    \"\"\"\n","    Evaluation loop for the multi-class classification problem.\n","    return (loss, accuracy)\n","    \"\"\"\n","    model.eval()\n","    losses = []\n","    accuracies = []\n","    pred_labels = []\n","    true_labels = []\n","    meta_info = []\n","\n","    with torch.no_grad():\n","        for i, (ids, masks, labels, meta) in enumerate(loader):\n","            ids = ids.to(device)\n","            masks = masks.to(device)\n","            labels = labels.to(device)\n","            \n","            # Forward pass\n","            outputs = model(ids,masks)\n","            loss = torch.nn.functional.cross_entropy(outputs, labels, reduce=None).detach()\n","            losses.append(loss.reshape(-1))\n","            preds = torch.argmax(outputs, dim=1)\n","            acc = (preds == labels).float().detach()\n","            pred_labels+=preds.detach().cpu().tolist()\n","            true_labels+=labels.detach().cpu().tolist()\n","            accuracies.append(acc.reshape(-1))\n","            meta_info.append(meta)\n","\n","        if benchmark_val:\n","          return torch.FloatTensor(pred_labels), torch.FloatTensor(true_labels), torch.cat(meta_info, dim=0)\n","\n","        losses = torch.cat(losses, dim=0).mean().cpu().data.numpy()\n","        accuracies = torch.cat(accuracies, dim=0).mean().cpu().data.numpy()\n","\n","        ## As the original paper used the macro F1 score to evaluate the fine-tuned models\n","        ## additional argument (cal_f1) defined to calculate macro F1 score within this function\n","        if cal_f1:\n","          p_macro, r_macro, f1_macro, support_macro = \\\n","                  precision_recall_fscore_support(y_true=np.array(true_labels), y_pred=np.array(pred_labels), average='macro')\n","          return losses, accuracies, p_macro, r_macro, f1_macro\n","        else:\n","          return losses, accuracies\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKnOiiNipDoH","executionInfo":{"status":"ok","timestamp":1651680734161,"user_tz":420,"elapsed":1051049,"user":{"displayName":"Han Kyul Kim","userId":"01874191508261431132"}},"outputId":"dce83e1e-9572-4d12-adb8-5af9df48fe91"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 20%|██        | 16814/84070 [1:08:08<4:33:52,  4.09it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["({'acc_avg': 0.7735121250152588, 'acc_y:0_male:1': 0.6661428809165955, 'count_y:0_male:1': 12092.0, 'acc_y:1_male:1': 0.9278256893157959, 'count_y:1_male:1': 2203.0, 'acc_y:0_female:1': 0.6740249395370483, 'count_y:0_female:1': 14179.0, 'acc_y:1_female:1': 0.9392070770263672, 'count_y:1_female:1': 2270.0, 'acc_y:0_LGBTQ:1': 0.4367601275444031, 'count_y:0_LGBTQ:1': 3210.0, 'acc_y:1_LGBTQ:1': 0.9350329041481018, 'count_y:1_LGBTQ:1': 1216.0, 'acc_y:0_christian:1': 0.7593587040901184, 'count_y:0_christian:1': 12101.0, 'acc_y:1_christian:1': 0.9198412895202637, 'count_y:1_christian:1': 1260.0, 'acc_y:0_muslim:1': 0.4154995381832123, 'count_y:0_muslim:1': 5355.0, 'acc_y:1_muslim:1': 0.9631223082542419, 'count_y:1_muslim:1': 1627.0, 'acc_y:0_other_religions:1': 0.6120805144309998, 'count_y:0_other_religions:1': 2980.0, 'acc_y:1_other_religions:1': 0.9307692050933838, 'count_y:1_other_religions:1': 520.0, 'acc_y:0_black:1': 0.6011993885040283, 'count_y:0_black:1': 3335.0, 'acc_y:1_black:1': 0.8724788427352905, 'count_y:1_black:1': 1537.0, 'acc_y:0_white:1': 0.43683382868766785, 'count_y:0_white:1': 5723.0, 'acc_y:1_white:1': 0.942119300365448, 'count_y:1_white:1': 2246.0, 'acc_wg': 0.4154995381832123}, 'Average acc: 0.774\\n  male                   acc on non_toxic: 0.666 (n =  12092)    acc on toxic: 0.928 (n =   2203) \\n  female                 acc on non_toxic: 0.674 (n =  14179)    acc on toxic: 0.939 (n =   2270) \\n  LGBTQ                  acc on non_toxic: 0.437 (n =   3210)    acc on toxic: 0.935 (n =   1216) \\n  christian              acc on non_toxic: 0.759 (n =  12101)    acc on toxic: 0.920 (n =   1260) \\n  muslim                 acc on non_toxic: 0.415 (n =   5355)    acc on toxic: 0.963 (n =   1627) \\n  other_religions        acc on non_toxic: 0.612 (n =   2980)    acc on toxic: 0.931 (n =    520) \\n  black                  acc on non_toxic: 0.601 (n =   3335)    acc on toxic: 0.872 (n =   1537) \\n  white                  acc on non_toxic: 0.437 (n =   5723)    acc on toxic: 0.942 (n =   2246) \\nWorst-group acc: 0.415\\n')\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 40%|████      | 33628/84070 [2:55:30<3:24:30,  4.11it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["({'acc_avg': 0.8805220723152161, 'acc_y:0_male:1': 0.8454350233078003, 'count_y:0_male:1': 12092.0, 'acc_y:1_male:1': 0.7898320555686951, 'count_y:1_male:1': 2203.0, 'acc_y:0_female:1': 0.8607800006866455, 'count_y:0_female:1': 14179.0, 'acc_y:1_female:1': 0.7960352301597595, 'count_y:1_female:1': 2270.0, 'acc_y:0_LGBTQ:1': 0.6834890842437744, 'count_y:0_LGBTQ:1': 3210.0, 'acc_y:1_LGBTQ:1': 0.8133223652839661, 'count_y:1_LGBTQ:1': 1216.0, 'acc_y:0_christian:1': 0.8909181356430054, 'count_y:0_christian:1': 12101.0, 'acc_y:1_christian:1': 0.7841269969940186, 'count_y:1_christian:1': 1260.0, 'acc_y:0_muslim:1': 0.7055088877677917, 'count_y:0_muslim:1': 5355.0, 'acc_y:1_muslim:1': 0.8322064876556396, 'count_y:1_muslim:1': 1627.0, 'acc_y:0_other_religions:1': 0.8130872249603271, 'count_y:0_other_religions:1': 2980.0, 'acc_y:1_other_religions:1': 0.7942307591438293, 'count_y:1_other_religions:1': 520.0, 'acc_y:0_black:1': 0.8413792848587036, 'count_y:0_black:1': 3335.0, 'acc_y:1_black:1': 0.6551724076271057, 'count_y:1_black:1': 1537.0, 'acc_y:0_white:1': 0.7013803720474243, 'count_y:0_white:1': 5723.0, 'acc_y:1_white:1': 0.7871772050857544, 'count_y:1_white:1': 2246.0, 'acc_wg': 0.6551724076271057}, 'Average acc: 0.881\\n  male                   acc on non_toxic: 0.845 (n =  12092)    acc on toxic: 0.790 (n =   2203) \\n  female                 acc on non_toxic: 0.861 (n =  14179)    acc on toxic: 0.796 (n =   2270) \\n  LGBTQ                  acc on non_toxic: 0.683 (n =   3210)    acc on toxic: 0.813 (n =   1216) \\n  christian              acc on non_toxic: 0.891 (n =  12101)    acc on toxic: 0.784 (n =   1260) \\n  muslim                 acc on non_toxic: 0.706 (n =   5355)    acc on toxic: 0.832 (n =   1627) \\n  other_religions        acc on non_toxic: 0.813 (n =   2980)    acc on toxic: 0.794 (n =    520) \\n  black                  acc on non_toxic: 0.841 (n =   3335)    acc on toxic: 0.655 (n =   1537) \\n  white                  acc on non_toxic: 0.701 (n =   5723)    acc on toxic: 0.787 (n =   2246) \\nWorst-group acc: 0.655\\n')\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 60%|██████    | 50442/84070 [4:42:49<2:15:52,  4.12it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["({'acc_avg': 0.8471618294715881, 'acc_y:0_male:1': 0.7859742045402527, 'count_y:0_male:1': 12092.0, 'acc_y:1_male:1': 0.8647299408912659, 'count_y:1_male:1': 2203.0, 'acc_y:0_female:1': 0.7973058819770813, 'count_y:0_female:1': 14179.0, 'acc_y:1_female:1': 0.8709251284599304, 'count_y:1_female:1': 2270.0, 'acc_y:0_LGBTQ:1': 0.5470405220985413, 'count_y:0_LGBTQ:1': 3210.0, 'acc_y:1_LGBTQ:1': 0.8824012875556946, 'count_y:1_LGBTQ:1': 1216.0, 'acc_y:0_christian:1': 0.8381952047348022, 'count_y:0_christian:1': 12101.0, 'acc_y:1_christian:1': 0.8444444537162781, 'count_y:1_christian:1': 1260.0, 'acc_y:0_muslim:1': 0.4750700294971466, 'count_y:0_muslim:1': 5355.0, 'acc_y:1_muslim:1': 0.9366933107376099, 'count_y:1_muslim:1': 1627.0, 'acc_y:0_other_religions:1': 0.7322147488594055, 'count_y:0_other_religions:1': 2980.0, 'acc_y:1_other_religions:1': 0.8615384697914124, 'count_y:1_other_religions:1': 520.0, 'acc_y:0_black:1': 0.7382308840751648, 'count_y:0_black:1': 3335.0, 'acc_y:1_black:1': 0.7716330289840698, 'count_y:1_black:1': 1537.0, 'acc_y:0_white:1': 0.5465664863586426, 'count_y:0_white:1': 5723.0, 'acc_y:1_white:1': 0.8820124864578247, 'count_y:1_white:1': 2246.0, 'acc_wg': 0.4750700294971466}, 'Average acc: 0.847\\n  male                   acc on non_toxic: 0.786 (n =  12092)    acc on toxic: 0.865 (n =   2203) \\n  female                 acc on non_toxic: 0.797 (n =  14179)    acc on toxic: 0.871 (n =   2270) \\n  LGBTQ                  acc on non_toxic: 0.547 (n =   3210)    acc on toxic: 0.882 (n =   1216) \\n  christian              acc on non_toxic: 0.838 (n =  12101)    acc on toxic: 0.844 (n =   1260) \\n  muslim                 acc on non_toxic: 0.475 (n =   5355)    acc on toxic: 0.937 (n =   1627) \\n  other_religions        acc on non_toxic: 0.732 (n =   2980)    acc on toxic: 0.862 (n =    520) \\n  black                  acc on non_toxic: 0.738 (n =   3335)    acc on toxic: 0.772 (n =   1537) \\n  white                  acc on non_toxic: 0.547 (n =   5723)    acc on toxic: 0.882 (n =   2246) \\nWorst-group acc: 0.475\\n')\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 80%|████████  | 67256/84070 [6:30:10<1:07:36,  4.15it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["({'acc_avg': 0.8457565307617188, 'acc_y:0_male:1': 0.7778696417808533, 'count_y:0_male:1': 12092.0, 'acc_y:1_male:1': 0.8597367405891418, 'count_y:1_male:1': 2203.0, 'acc_y:0_female:1': 0.7894068956375122, 'count_y:0_female:1': 14179.0, 'acc_y:1_female:1': 0.8647577166557312, 'count_y:1_female:1': 2270.0, 'acc_y:0_LGBTQ:1': 0.5442367792129517, 'count_y:0_LGBTQ:1': 3210.0, 'acc_y:1_LGBTQ:1': 0.8807565569877625, 'count_y:1_LGBTQ:1': 1216.0, 'acc_y:0_christian:1': 0.8417485952377319, 'count_y:0_christian:1': 12101.0, 'acc_y:1_christian:1': 0.8460317254066467, 'count_y:1_christian:1': 1260.0, 'acc_y:0_muslim:1': 0.6244631409645081, 'count_y:0_muslim:1': 5355.0, 'acc_y:1_muslim:1': 0.8733866214752197, 'count_y:1_muslim:1': 1627.0, 'acc_y:0_other_religions:1': 0.7640939354896545, 'count_y:0_other_religions:1': 2980.0, 'acc_y:1_other_religions:1': 0.8480769395828247, 'count_y:1_other_religions:1': 520.0, 'acc_y:0_black:1': 0.7586206793785095, 'count_y:0_black:1': 3335.0, 'acc_y:1_black:1': 0.7495120167732239, 'count_y:1_black:1': 1537.0, 'acc_y:0_white:1': 0.553381085395813, 'count_y:0_white:1': 5723.0, 'acc_y:1_white:1': 0.8664292097091675, 'count_y:1_white:1': 2246.0, 'acc_wg': 0.5442367792129517}, 'Average acc: 0.846\\n  male                   acc on non_toxic: 0.778 (n =  12092)    acc on toxic: 0.860 (n =   2203) \\n  female                 acc on non_toxic: 0.789 (n =  14179)    acc on toxic: 0.865 (n =   2270) \\n  LGBTQ                  acc on non_toxic: 0.544 (n =   3210)    acc on toxic: 0.881 (n =   1216) \\n  christian              acc on non_toxic: 0.842 (n =  12101)    acc on toxic: 0.846 (n =   1260) \\n  muslim                 acc on non_toxic: 0.624 (n =   5355)    acc on toxic: 0.873 (n =   1627) \\n  other_religions        acc on non_toxic: 0.764 (n =   2980)    acc on toxic: 0.848 (n =    520) \\n  black                  acc on non_toxic: 0.759 (n =   3335)    acc on toxic: 0.750 (n =   1537) \\n  white                  acc on non_toxic: 0.553 (n =   5723)    acc on toxic: 0.866 (n =   2246) \\nWorst-group acc: 0.544\\n')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 84070/84070 [8:56:41<00:00,  2.61it/s]"]},{"output_type":"stream","name":"stdout","text":["({'acc_avg': 0.8430581092834473, 'acc_y:0_male:1': 0.777125358581543, 'count_y:0_male:1': 12092.0, 'acc_y:1_male:1': 0.8597367405891418, 'count_y:1_male:1': 2203.0, 'acc_y:0_female:1': 0.7860921025276184, 'count_y:0_female:1': 14179.0, 'acc_y:1_female:1': 0.8744493126869202, 'count_y:1_female:1': 2270.0, 'acc_y:0_LGBTQ:1': 0.5124610662460327, 'count_y:0_LGBTQ:1': 3210.0, 'acc_y:1_LGBTQ:1': 0.8922697305679321, 'count_y:1_LGBTQ:1': 1216.0, 'acc_y:0_christian:1': 0.8220807909965515, 'count_y:0_christian:1': 12101.0, 'acc_y:1_christian:1': 0.8698412775993347, 'count_y:1_christian:1': 1260.0, 'acc_y:0_muslim:1': 0.5512605309486389, 'count_y:0_muslim:1': 5355.0, 'acc_y:1_muslim:1': 0.8998156189918518, 'count_y:1_muslim:1': 1627.0, 'acc_y:0_other_religions:1': 0.7271811962127686, 'count_y:0_other_religions:1': 2980.0, 'acc_y:1_other_religions:1': 0.8615384697914124, 'count_y:1_other_religions:1': 520.0, 'acc_y:0_black:1': 0.7946026921272278, 'count_y:0_black:1': 3335.0, 'acc_y:1_black:1': 0.6948601007461548, 'count_y:1_black:1': 1537.0, 'acc_y:0_white:1': 0.5795910954475403, 'count_y:0_white:1': 5723.0, 'acc_y:1_white:1': 0.8437221646308899, 'count_y:1_white:1': 2246.0, 'acc_wg': 0.5124610662460327}, 'Average acc: 0.843\\n  male                   acc on non_toxic: 0.777 (n =  12092)    acc on toxic: 0.860 (n =   2203) \\n  female                 acc on non_toxic: 0.786 (n =  14179)    acc on toxic: 0.874 (n =   2270) \\n  LGBTQ                  acc on non_toxic: 0.512 (n =   3210)    acc on toxic: 0.892 (n =   1216) \\n  christian              acc on non_toxic: 0.822 (n =  12101)    acc on toxic: 0.870 (n =   1260) \\n  muslim                 acc on non_toxic: 0.551 (n =   5355)    acc on toxic: 0.900 (n =   1627) \\n  other_religions        acc on non_toxic: 0.727 (n =   2980)    acc on toxic: 0.862 (n =    520) \\n  black                  acc on non_toxic: 0.795 (n =   3335)    acc on toxic: 0.695 (n =   1537) \\n  white                  acc on non_toxic: 0.580 (n =   5723)    acc on toxic: 0.844 (n =   2246) \\nWorst-group acc: 0.512\\n')\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["## Defining step sizes in DRO\n","eta_q = 0.01\n","\n","RESULT_FOLDER = \"./drive/MyDrive/CS699/homework #3/DRO\"\n","os.makedirs(f\"{RESULT_FOLDER}/{pretrained_path}/\", exist_ok=True)\n","\n","device = torch.device(\"cuda\")\n","\n","with tqdm(total=epochs*len(train_loader)) as pbar:\n","  for epoch in range(epochs):\n","    model.train()\n","    \n","    for i, batch in enumerate(train_loader):\n","      selected_group = random.randint(0, (batch_size//n_groups) - 1)\n","      selected_idx = selected_group * 4\n","\n","      batch_text = batch[0][selected_idx:selected_idx+4]#.to(device)\n","      d_labels = batch[1][selected_idx:selected_idx+4].to(device)\n","\n","      tokenized_text = roberta_tokenizer(batch_text, truncation=True, max_length = 300, padding='max_length', return_tensors = 'pt', return_attention_mask = True)\n","      d_input_id = tokenized_text['input_ids'].to(device)\n","      d_att_mask = tokenized_text['attention_mask'].to(device)\n","      \n","      outputs = model(d_input_id,d_att_mask)\n","      loss = torch.nn.functional.cross_entropy(outputs, d_labels)\n","\n","      group_weights = update_dro_group_weights(group_weights, selected_group, loss, eta_q = eta_q)\n","      optimizer.param_groups[0]['lr'] = 1e-5 * group_weights[selected_group]\n","\n","      model.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      pbar.update(1)\n","\n","\n","    torch.save(\n","        model.state_dict(), f'{RESULT_FOLDER}/{pretrained_path}/{epoch + 1}_model.pt',\n","        pickle_module=dill\n","    )\n","    \n","    pred, label, meta = get_loss_value(model, test_dataloader, device=device, benchmark_val=True)\n","    print(dataset.eval(pred, label, meta))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WeyDkSFbcQv7"},"outputs":[],"source":["import glob\n","pretrained_path = 'roberta-base'\n","model_path  = glob.glob(f\"/home/hhamad/CSCI699-HW1/homework3/log/{pretrained_path}/*\")\n","\n","device = torch.device(\"cuda\")\n","\n","def load_ckp(checkpoint_fpath, model):\n","    checkpoint = torch.load(checkpoint_fpath)\n","    model.load_state_dict(checkpoint)\n","    return model\n","\n","for ckp_path in model_path:\n","  print(ckp_path)\n","  model = load_ckp(ckp_path, model)\n","  #loss, acc, prec, recall, f1 = get_loss_value(model, test_dataloader, device=device, benchmark_val=True)\n","  pred, label, meta = get_loss_value(model, test_dataloader, device=device, benchmark_val=True)\n","  #print(\"\\t Loss: %f, Accuracy on the test dataset: %f\" %(loss, acc))\n","  #print(\"\\t prec: %f, recall: %f, macro f1: %f\" %(prec, recall, f1))\n","  print(dataset.eval(pred, label, meta))\n","  print('--------------------------')\n"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"groupDRO_roberta_finetuned_tweets_hate_speech_corrected.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6b32ad6b10f543e8bc49851e16c1ce9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bf91d720fe14e27acd2d375af3fb1f1","IPY_MODEL_62f59acb0d124f6385e2b9a0c54f85cd","IPY_MODEL_1022ac87ba3d4cc0892452194f00406e"],"layout":"IPY_MODEL_9f4624370d6540c0b9afc1d4c5796e97"}},"2bf91d720fe14e27acd2d375af3fb1f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8518c15001c4a7b8c000ba39cb15a69","placeholder":"​","style":"IPY_MODEL_a62aadd82fc749ecbb29af1518618bf7","value":""}},"62f59acb0d124f6385e2b9a0c54f85cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f564e8ccbb43420a9f9e1290b7915dc2","max":90644480,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5c111bb676f4c06b91d4bedea1e778d","value":90644480}},"1022ac87ba3d4cc0892452194f00406e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de53d9765d1f4e9a930aeec6c3dbad0c","placeholder":"​","style":"IPY_MODEL_f998fdbe823b466aa1f4bff240ef49a8","value":" 90914816/? [00:22&lt;00:00, 5632856.74Byte/s]"}},"9f4624370d6540c0b9afc1d4c5796e97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8518c15001c4a7b8c000ba39cb15a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a62aadd82fc749ecbb29af1518618bf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f564e8ccbb43420a9f9e1290b7915dc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c111bb676f4c06b91d4bedea1e778d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de53d9765d1f4e9a930aeec6c3dbad0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f998fdbe823b466aa1f4bff240ef49a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d97ce080ec154d709c94dbe4a8d0c438":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb85a75cc7264b85912cda280739aa07","IPY_MODEL_bf39e55f3b964d75af10e09e5aa07425","IPY_MODEL_21b9df91c02841068b8ad5c28ed9e9db"],"layout":"IPY_MODEL_f2c031f1986e4363b7181bbbbdcb4fc8"}},"eb85a75cc7264b85912cda280739aa07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b57117704fb4b2aa8e007a2fbb21228","placeholder":"​","style":"IPY_MODEL_6084c8701e5742b28207df5b3c98128e","value":"Downloading: 100%"}},"bf39e55f3b964d75af10e09e5aa07425":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11064a9a79cf4f86849f453f2980f863","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d62fd52723114272975191b19a020691","value":898822}},"21b9df91c02841068b8ad5c28ed9e9db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0fb3c7d1fe4882892c822bccea98ed","placeholder":"​","style":"IPY_MODEL_2e3580f2593247489af95d1f8b6e8fd8","value":" 878k/878k [00:01&lt;00:00, 948kB/s]"}},"f2c031f1986e4363b7181bbbbdcb4fc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b57117704fb4b2aa8e007a2fbb21228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6084c8701e5742b28207df5b3c98128e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11064a9a79cf4f86849f453f2980f863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d62fd52723114272975191b19a020691":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c0fb3c7d1fe4882892c822bccea98ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e3580f2593247489af95d1f8b6e8fd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d5bcfed84314667af43ebb0229c5fbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48b14ad5ead84b00887fc4153409c68d","IPY_MODEL_943138710e204e7dad11089b20a98ed6","IPY_MODEL_9c777e19dd2d450192135e02fcc1b341"],"layout":"IPY_MODEL_bc60116278ec4e89bc193d81f5a36216"}},"48b14ad5ead84b00887fc4153409c68d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d318ec5555cc4fa4a167729bdb017d31","placeholder":"​","style":"IPY_MODEL_2cee70c7bb414cbbbdf20690045feba2","value":"Downloading: 100%"}},"943138710e204e7dad11089b20a98ed6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33251e95ea4b42b0867061dfeb1ecdb7","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_833d74219db54a35aa575c3ae0592114","value":456318}},"9c777e19dd2d450192135e02fcc1b341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29a4c253c3bb43af8b8d72633ac758ba","placeholder":"​","style":"IPY_MODEL_e77bc7140a1541f584d8872554d34bfc","value":" 446k/446k [00:01&lt;00:00, 533kB/s]"}},"bc60116278ec4e89bc193d81f5a36216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d318ec5555cc4fa4a167729bdb017d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cee70c7bb414cbbbdf20690045feba2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33251e95ea4b42b0867061dfeb1ecdb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"833d74219db54a35aa575c3ae0592114":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29a4c253c3bb43af8b8d72633ac758ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e77bc7140a1541f584d8872554d34bfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"765293faad974c03971bb3a2811b4290":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_122201fb63204aa0a54a4d3ccf86d05e","IPY_MODEL_1a1a04bb77ee4f6186fc6e1a6175c42e","IPY_MODEL_349d957b327d4aa99526d32f26684c4c"],"layout":"IPY_MODEL_a185fba62ae2465ea7fa4808947965da"}},"122201fb63204aa0a54a4d3ccf86d05e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f76ae4ef25b499e9c7089e78ff946ad","placeholder":"​","style":"IPY_MODEL_1914fd59c5764ad08e74e141eee0df31","value":"Downloading: 100%"}},"1a1a04bb77ee4f6186fc6e1a6175c42e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_620c5ce50e2349f6ac72ce78de3c2661","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12133a9573344dd7824a3d38634e894a","value":150}},"349d957b327d4aa99526d32f26684c4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5bf34ff38c049c48803c45b94e60c8c","placeholder":"​","style":"IPY_MODEL_63ced2dcecf64e1583ac216d51df9e5a","value":" 150/150 [00:00&lt;00:00, 5.82kB/s]"}},"a185fba62ae2465ea7fa4808947965da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f76ae4ef25b499e9c7089e78ff946ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1914fd59c5764ad08e74e141eee0df31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"620c5ce50e2349f6ac72ce78de3c2661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12133a9573344dd7824a3d38634e894a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5bf34ff38c049c48803c45b94e60c8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63ced2dcecf64e1583ac216d51df9e5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccd22bbdd0684b14aae8aba6d6feb759":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_095d03243fbd48abb7028a40a5189a03","IPY_MODEL_467148aae83b44f583ccecd4744658ae","IPY_MODEL_c07de1b836ec4f0babd8231971983249"],"layout":"IPY_MODEL_1113ae58f9b943d09f6bf05ca6ce5f77"}},"095d03243fbd48abb7028a40a5189a03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2cfda63d4ef406dad587a99ddb25afd","placeholder":"​","style":"IPY_MODEL_a1228479026145f29b3907acd342461f","value":"Downloading: 100%"}},"467148aae83b44f583ccecd4744658ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ad83da36c31467fb16af45dc9c5858e","max":588,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c4d23da48e04d5284e0c815e2c04bf4","value":588}},"c07de1b836ec4f0babd8231971983249":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ce51963f3b2487783d40ed62eccc714","placeholder":"​","style":"IPY_MODEL_046a7dc6b1314b94aa5a2f85a0f72eb9","value":" 588/588 [00:00&lt;00:00, 23.9kB/s]"}},"1113ae58f9b943d09f6bf05ca6ce5f77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2cfda63d4ef406dad587a99ddb25afd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1228479026145f29b3907acd342461f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ad83da36c31467fb16af45dc9c5858e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c4d23da48e04d5284e0c815e2c04bf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ce51963f3b2487783d40ed62eccc714":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"046a7dc6b1314b94aa5a2f85a0f72eb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c70c1ba369ad4aeda31aa32c38d59f59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_267e944116154affbaeb86b71b113df8","IPY_MODEL_50a832c3a6fb4e6cba70939b45038f2e","IPY_MODEL_a339c186931043fcad4194efb637f278"],"layout":"IPY_MODEL_b4f402b84c584c67a5f256714085ffc8"}},"267e944116154affbaeb86b71b113df8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b6e6304facb45eb85f39976d611421d","placeholder":"​","style":"IPY_MODEL_c2fa3636ab40445da36682777d0e923b","value":"Downloading: 100%"}},"50a832c3a6fb4e6cba70939b45038f2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95b39bba22c84fbdb2805489758148e5","max":498676425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a966bf5a040a418fb0fa31e3fca6ac80","value":498676425}},"a339c186931043fcad4194efb637f278":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_486396b80928466db7d372f969fbaa34","placeholder":"​","style":"IPY_MODEL_d37a736d32794c9e8600404a4b6a793a","value":" 476M/476M [00:25&lt;00:00, 24.2MB/s]"}},"b4f402b84c584c67a5f256714085ffc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b6e6304facb45eb85f39976d611421d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2fa3636ab40445da36682777d0e923b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95b39bba22c84fbdb2805489758148e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a966bf5a040a418fb0fa31e3fca6ac80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"486396b80928466db7d372f969fbaa34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d37a736d32794c9e8600404a4b6a793a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}